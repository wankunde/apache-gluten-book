#!/usr/bin/env python3
"""
Apache Gluten Fallback åŸå› åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. è§£æ Spark UI å’Œæ‰§è¡Œè®¡åˆ’æ—¥å¿—
2. è‡ªåŠ¨åˆ†ç±» Fallback åŸå› 
3. ç»Ÿè®¡ Fallback æ¨¡å¼
4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š

ç›¸å…³ç« èŠ‚ï¼šç¬¬9ç«  - Fallback æœºåˆ¶

ä½¿ç”¨ï¼š
```bash
python code-examples/python/fallback_analysis.py --log spark-events.log
python code-examples/python/fallback_analysis.py --plan plan.txt --output report.html
```

ä¾èµ–ï¼š
pip install pandas matplotlib
"""

import re
import json
import argparse
from collections import Counter, defaultdict
from typing import List, Dict, Tuple
from dataclasses import dataclass
from pathlib import Path

@dataclass
class FallbackCase:
    """Fallback æ¡ˆä¾‹"""
    query_id: str
    operator: str
    reason: str
    category: str
    location: str
    severity: str  # 'high', 'medium', 'low'

class FallbackAnalyzer:
    """Fallback åˆ†æå™¨"""
    
    # Fallback æ¨¡å¼åŒ¹é…è§„åˆ™
    PATTERNS = {
        'udf': (r'UDF|UserDefinedFunction', 'UDF ä¸æ”¯æŒ'),
        'window': (r'Window|WindowExec', 'çª—å£å‡½æ•°'),
        'sort': (r'Sort|SortExec', 'æ’åºç®—å­'),
        'aggregate': (r'Aggregate|HashAggregate', 'èšåˆå‡½æ•°'),
        'join': (r'Join|BroadcastHashJoin|SortMergeJoin', 'Join ç®—å­'),
        'c2r': (r'ColumnarToRow', 'åˆ—è½¬è¡Œ'),
        'r2c': (r'RowToColumnar', 'è¡Œè½¬åˆ—'),
        'datatype': (r'DecimalType|MapType|StructType', 'æ•°æ®ç±»å‹ä¸æ”¯æŒ'),
        'unknown': (r'.*', 'æœªçŸ¥åŸå› ')
    }
    
    def __init__(self):
        self.fallback_cases: List[FallbackCase] = []
        self.statistics = defaultdict(int)
        
    def parse_execution_plan(self, plan_text: str, query_id: str = "default") -> List[FallbackCase]:
        """è§£ææ‰§è¡Œè®¡åˆ’ï¼Œæå– Fallback ä¿¡æ¯"""
        cases = []
        lines = plan_text.split('\n')
        
        for i, line in enumerate(lines):
            # æ£€æµ‹ ColumnarToRow å’Œ RowToColumnar
            if 'ColumnarToRow' in line or 'RowToColumnar' in line:
                operator = 'ColumnarToRow' if 'ColumnarToRow' in line else 'RowToColumnar'
                
                # å°è¯•æå–ä¸Šä¸‹æ–‡
                context_start = max(0, i - 2)
                context_end = min(len(lines), i + 3)
                context = '\n'.join(lines[context_start:context_end])
                
                # åˆ†æåŸå› 
                reason, category = self._classify_fallback(context)
                severity = self._assess_severity(operator, category)
                
                case = FallbackCase(
                    query_id=query_id,
                    operator=operator,
                    reason=reason,
                    category=category,
                    location=line.strip()[:100],
                    severity=severity
                )
                cases.append(case)
                self.fallback_cases.append(case)
                self.statistics[category] += 1
        
        return cases
    
    def _classify_fallback(self, context: str) -> Tuple[str, str]:
        """åˆ†ç±» Fallback åŸå› """
        for category, (pattern, reason) in self.PATTERNS.items():
            if re.search(pattern, context, re.IGNORECASE):
                return reason, category
        return "æœªçŸ¥åŸå› ", "unknown"
    
    def _assess_severity(self, operator: str, category: str) -> str:
        """è¯„ä¼° Fallback ä¸¥é‡ç¨‹åº¦"""
        high_severity = ['udf', 'aggregate', 'join']
        medium_severity = ['window', 'sort', 'datatype']
        
        if category in high_severity:
            return 'high'
        elif category in medium_severity:
            return 'medium'
        else:
            return 'low'
    
    def parse_log_file(self, log_path: str) -> None:
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        print(f"[INFO] è§£ææ—¥å¿—æ–‡ä»¶: {log_path}")
        
        with open(log_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’
        plan_blocks = re.findall(r'=== Physical Plan ===(.+?)(?:===|$)', content, re.DOTALL)
        
        for idx, plan in enumerate(plan_blocks):
            query_id = f"query_{idx + 1}"
            self.parse_execution_plan(plan, query_id)
        
        print(f"[INFO] å‘ç° {len(self.fallback_cases)} ä¸ª Fallback æ¡ˆä¾‹")
    
    def generate_report(self, output_format: str = 'text') -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if output_format == 'text':
            return self._generate_text_report()
        elif output_format == 'json':
            return self._generate_json_report()
        elif output_format == 'html':
            return self._generate_html_report()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_format}")
    
    def _generate_text_report(self) -> str:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 70)
        lines.append("          Apache Gluten Fallback åˆ†ææŠ¥å‘Š")
        lines.append("=" * 70)
        lines.append("")
        
        # ç»Ÿè®¡æ¦‚è§ˆ
        lines.append("â”â”â” ç»Ÿè®¡æ¦‚è§ˆ â”â”â”")
        lines.append("")
        lines.append(f"æ€» Fallback æ•°: {len(self.fallback_cases)}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        lines.append("\næŒ‰ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in sorted(self.statistics.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(self.fallback_cases) * 100 if self.fallback_cases else 0
            lines.append(f"  â€¢ {category:15s}: {count:3d} ({percentage:5.1f}%)")
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
        severity_count = Counter(case.severity for case in self.fallback_cases)
        lines.append("\næŒ‰ä¸¥é‡ç¨‹åº¦:")
        for severity in ['high', 'medium', 'low']:
            count = severity_count.get(severity, 0)
            percentage = count / len(self.fallback_cases) * 100 if self.fallback_cases else 0
            icon = "ğŸ”´" if severity == 'high' else "ğŸŸ¡" if severity == 'medium' else "ğŸŸ¢"
            lines.append(f"  {icon} {severity.upper():6s}: {count:3d} ({percentage:5.1f}%)")
        
        # è¯¦ç»†æ¡ˆä¾‹
        if self.fallback_cases:
            lines.append("\nâ”â”â” Fallback è¯¦æƒ… (å‰10ä¸ª) â”â”â”\n")
            for i, case in enumerate(self.fallback_cases[:10], 1):
                severity_icon = "ğŸ”´" if case.severity == 'high' else "ğŸŸ¡" if case.severity == 'medium' else "ğŸŸ¢"
                lines.append(f"[{i}] {severity_icon} {case.operator}")
                lines.append(f"    æŸ¥è¯¢: {case.query_id}")
                lines.append(f"    åŸå› : {case.reason} ({case.category})")
                lines.append(f"    ä½ç½®: {case.location}")
                lines.append("")
        
        # ä¼˜åŒ–å»ºè®®
        lines.append("â”â”â” ä¼˜åŒ–å»ºè®® â”â”â”\n")
        lines.extend(self._generate_recommendations())
        
        return '\n'.join(lines)
    
    def _generate_json_report(self) -> str:
        """ç”Ÿæˆ JSON æŠ¥å‘Š"""
        report = {
            "summary": {
                "total_fallbacks": len(self.fallback_cases),
                "by_category": dict(self.statistics),
                "by_severity": dict(Counter(case.severity for case in self.fallback_cases))
            },
            "cases": [
                {
                    "query_id": case.query_id,
                    "operator": case.operator,
                    "reason": case.reason,
                    "category": case.category,
                    "severity": case.severity,
                    "location": case.location
                }
                for case in self.fallback_cases
            ],
            "recommendations": self._generate_recommendations()
        }
        return json.dumps(report, indent=2, ensure_ascii=False)
    
    def _generate_html_report(self) -> str:
        """ç”Ÿæˆ HTML æŠ¥å‘Š"""
        html = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Gluten Fallback åˆ†ææŠ¥å‘Š</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; }
        h1 { color: #1a73e8; border-bottom: 3px solid #1a73e8; padding-bottom: 10px; }
        h2 { color: #333; margin-top: 30px; }
        .stat-box { display: inline-block; margin: 10px; padding: 20px; background: #f0f7ff; border-radius: 8px; min-width: 150px; }
        .stat-number { font-size: 36px; font-weight: bold; color: #1a73e8; }
        .stat-label { color: #666; margin-top: 5px; }
        table { width: 100%; border-collapse: collapse; margin-top: 20px; }
        th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }
        th { background: #1a73e8; color: white; }
        tr:hover { background: #f5f5f5; }
        .high { color: #d93025; font-weight: bold; }
        .medium { color: #f9ab00; font-weight: bold; }
        .low { color: #1e8e3e; }
        .recommendation { background: #fff3cd; padding: 15px; border-left: 4px solid #f9ab00; margin: 10px 0; }
        .chart { margin: 20px 0; padding: 20px; background: #f9f9f9; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ” Apache Gluten Fallback åˆ†ææŠ¥å‘Š</h1>
        
        <h2>ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ</h2>
        <div>
            <div class="stat-box">
                <div class="stat-number">{total_fallbacks}</div>
                <div class="stat-label">æ€» Fallback æ•°</div>
            </div>
            <div class="stat-box">
                <div class="stat-number">{high_severity}</div>
                <div class="stat-label">é«˜ä¼˜å…ˆçº§</div>
            </div>
            <div class="stat-box">
                <div class="stat-number">{medium_severity}</div>
                <div class="stat-label">ä¸­ä¼˜å…ˆçº§</div>
            </div>
            <div class="stat-box">
                <div class="stat-number">{low_severity}</div>
                <div class="stat-label">ä½ä¼˜å…ˆçº§</div>
            </div>
        </div>
        
        <h2>ğŸ“‹ ç±»åˆ«åˆ†å¸ƒ</h2>
        <table>
            <tr><th>ç±»åˆ«</th><th>æ•°é‡</th><th>å æ¯”</th></tr>
            {category_rows}
        </table>
        
        <h2>ğŸ” Fallback è¯¦æƒ…</h2>
        <table>
            <tr><th>æŸ¥è¯¢ID</th><th>ç®—å­</th><th>åŸå› </th><th>ä¸¥é‡ç¨‹åº¦</th></tr>
            {detail_rows}
        </table>
        
        <h2>ğŸ’¡ ä¼˜åŒ–å»ºè®®</h2>
        {recommendations}
    </div>
</body>
</html>
"""
        
        severity_count = Counter(case.severity for case in self.fallback_cases)
        
        # ç±»åˆ«è¡Œ
        category_rows = ""
        for category, count in sorted(self.statistics.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(self.fallback_cases) * 100 if self.fallback_cases else 0
            category_rows += f"<tr><td>{category}</td><td>{count}</td><td>{percentage:.1f}%</td></tr>\n"
        
        # è¯¦æƒ…è¡Œ
        detail_rows = ""
        for case in self.fallback_cases[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
            severity_class = case.severity
            detail_rows += f"""<tr>
                <td>{case.query_id}</td>
                <td>{case.operator}</td>
                <td>{case.reason}</td>
                <td class="{severity_class}">{case.severity.upper()}</td>
            </tr>\n"""
        
        # å»ºè®®
        recommendations = ""
        for rec in self._generate_recommendations():
            recommendations += f'<div class="recommendation">{rec}</div>\n'
        
        return html.format(
            total_fallbacks=len(self.fallback_cases),
            high_severity=severity_count.get('high', 0),
            medium_severity=severity_count.get('medium', 0),
            low_severity=severity_count.get('low', 0),
            category_rows=category_rows,
            detail_rows=detail_rows,
            recommendations=recommendations
        )
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if 'udf' in self.statistics:
            recommendations.append(
                "ğŸ”´ é«˜ä¼˜å…ˆçº§: å‘ç° UDF Fallbackã€‚å»ºè®®:\n"
                "   â€¢ ä½¿ç”¨ Velox UDF æˆ– ClickHouse UDF æ›¿ä»£ Scala/Java UDF\n"
                "   â€¢ å¦‚æœå¯èƒ½ï¼Œç”¨ SQL è¡¨è¾¾å¼æ›¿æ¢ UDF é€»è¾‘"
            )
        
        if 'aggregate' in self.statistics or 'join' in self.statistics:
            recommendations.append(
                "ğŸŸ¡ ä¸­ä¼˜å…ˆçº§: èšåˆæˆ– Join ç®—å­ Fallbackã€‚å»ºè®®:\n"
                "   â€¢ æ£€æŸ¥ä½¿ç”¨çš„èšåˆå‡½æ•°æ˜¯å¦åœ¨ Gluten æ”¯æŒåˆ—è¡¨ä¸­\n"
                "   â€¢ å°è¯•ä¸åŒçš„ Join ç­–ç•¥ (Broadcast vs SortMerge)\n"
                "   â€¢ å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬çš„ Gluten"
            )
        
        if 'datatype' in self.statistics:
            recommendations.append(
                "ğŸŸ¡ ä¸­ä¼˜å…ˆçº§: æ•°æ®ç±»å‹ä¸æ”¯æŒã€‚å»ºè®®:\n"
                "   â€¢ é¿å…ä½¿ç”¨å¤æ‚æ•°æ®ç±»å‹ (Map, Struct, Decimal)\n"
                "   â€¢ è€ƒè™‘æ•°æ®æ¨¡å‹ä¼˜åŒ–ï¼Œæ‰å¹³åŒ–åµŒå¥—ç»“æ„"
            )
        
        c2r_count = sum(1 for case in self.fallback_cases if case.operator == 'ColumnarToRow')
        if c2r_count > len(self.fallback_cases) * 0.3:
            recommendations.append(
                "ğŸ”´ é«˜ä¼˜å…ˆçº§: ColumnarToRow æ¯”ä¾‹è¿‡é«˜ã€‚å»ºè®®:\n"
                "   â€¢ æ£€æŸ¥æŸ¥è¯¢é€»è¾‘ï¼Œå‡å°‘è¡Œåˆ—è½¬æ¢\n"
                "   â€¢ é‡æ–°ç»„ç»‡æŸ¥è¯¢ï¼Œè®©æ›´å¤šæ“ä½œåœ¨åˆ—å¼å¼•æ“ä¸­å®Œæˆ"
            )
        
        if not recommendations:
            recommendations.append("âœ… å½“å‰ Fallback æƒ…å†µè‰¯å¥½ï¼Œå»ºè®®ç»§ç»­å…³æ³¨æ–°æŸ¥è¯¢çš„æ‰§è¡Œæƒ…å†µ")
        
        return recommendations
    
    def export_to_file(self, output_path: str, output_format: str = 'text') -> None:
        """å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.generate_report(output_format)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"[INFO] æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")

def main():
    parser = argparse.ArgumentParser(description='Gluten Fallback åˆ†æå·¥å…·')
    parser.add_argument('--log', help='Spark æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--plan', help='æ‰§è¡Œè®¡åˆ’æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', default='fallback_report.txt', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['text', 'json', 'html'], default='text', help='è¾“å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    analyzer = FallbackAnalyzer()
    
    if args.log:
        analyzer.parse_log_file(args.log)
    elif args.plan:
        with open(args.plan, 'r', encoding='utf-8') as f:
            plan_text = f.read()
        analyzer.parse_execution_plan(plan_text)
    else:
        # æ¼”ç¤ºæ¨¡å¼
        print("[INFO] æ¼”ç¤ºæ¨¡å¼ - ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\n")
        demo_plan = """
        == Physical Plan ==
        *(2) HashAggregate(keys=[category#10], functions=[sum(amount#11)])
        +- Exchange hashpartitioning(category#10, 200)
           +- *(1) HashAggregate(keys=[category#10], functions=[partial_sum(amount#11)])
              +- *(1) ColumnarToRow
                 +- FileScan parquet [category#10,amount#11]
        
        *(3) Project [id#20, custom_udf(value#21) AS result#30]
        +- *(3) ColumnarToRow
           +- WholeStageCodegen (2)
        """
        analyzer.parse_execution_plan(demo_plan, "demo_query")
    
    # ç”ŸæˆæŠ¥å‘Š
    if analyzer.fallback_cases:
        analyzer.export_to_file(args.output, args.format)
        
        # æ§åˆ¶å°è¾“å‡ºæ‘˜è¦
        print("\n" + analyzer.generate_report('text'))
    else:
        print("[INFO] æœªå‘ç° Fallback æ¡ˆä¾‹")

if __name__ == '__main__':
    main()
